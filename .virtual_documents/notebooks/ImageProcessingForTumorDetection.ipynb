








%pip install -r ../requirements.txt


import glob
import cv2

def read_images(images_path):
    """
    Reads all images from a specified path using OpenCV.

    Parameters:
        - images_path (str): The path to the directory containing the images.
    Returns:
        - images (list): A list of images read from the directory.
    """
    images = []
    for file_path in images_path:
        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
        if image is not None:
                images.append(image)
    return images





# Define the path to the dataset
dataset_path = '../data/brain_tumor_dataset/'

# List all image files in the 'yes' and 'no' directories
yes_images = glob.glob(dataset_path + 'yes/*.jpg')
no_images = glob.glob(dataset_path + 'no/*.jpg')

yes_images = read_images(yes_images)
no_images = read_images(no_images)

print(f"Number of 'yes' images: {len(yes_images)}")
print(f"Number of 'no' images: {len(no_images)}")





from skimage.filters.rank import entropy
from skimage.morphology import disk
from scipy import ndimage as nd
from skimage.filters import sobel, gabor, hessian, prewitt
import matplotlib.pyplot as plt


image = yes_images[0]

# Apply filters
entropy_img = entropy(image, disk(2))
gaussian_img = nd.gaussian_filter(image, sigma=1)
sobel_img = sobel(image)
gabor_img = gabor(image, frequency=0.9)[1]
hessian_img = hessian(image, sigmas=range(1, 100, 1))
prewitt_img = prewitt(image)

# Store the original and filtered images in a dictionary
filtered_images = {
    'Original': image,
    'Entropy': entropy_img,
    'Gaussian': gaussian_img,
    'Sobel': sobel_img,
    'Gabor': gabor_img,
    'Hessian': hessian_img,
    'Prewitt': prewitt_img
}





# Display each filtered image
plt.figure(figsize=(18, 3))
for i, (filter_name, filtered_image) in enumerate(filtered_images.items()):
        plt.subplot(1, len(filtered_images), i + 1)
        plt.imshow(filtered_image, cmap='gray')
        plt.title(filter_name)
        plt.axis('off')
plt.show()





## The sequential version

import time
from tqdm import tqdm

def process_images(images):
    processed_images = []
    for image in tqdm(images[:5]):
        filtered_images = {
            'Original': image,
            'Entropy': entropy(image, disk(2)),
            'Gaussian': nd.gaussian_filter(image, sigma=1),
            'Sobel': sobel(image),
            'Gabor': gabor(image, frequency=0.9)[1],
            'Hessian': hessian(image, sigmas=range(1, 100, 1)),
            'Prewitt': prewitt(image)
        }
        processed_images.append(filtered_images)
    return processed_images

# Example usage
start_time = time.time()
yes_inputs = process_images(yes_images)
no_inputs = process_images(no_images)
end_time = time.time()

execution_time = end_time - start_time
print(f"Sequential execution time: {execution_time} seconds")



import multiprocessing
import time
import threading
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from tqdm import tqdm

# Example imports from scikit-image (adjust to your real imports)
from skimage.filters import sobel, prewitt, gabor, hessian
from skimage.filters.rank import entropy
from skimage.morphology import disk
import scipy.ndimage as nd

# ------------------------------------------------------------------
# 1. Filter functions
#    (Each filter is its own function as requested)
# ------------------------------------------------------------------
def apply_entropy(image):
    """Apply entropy filter."""
    return entropy(image, disk(2))

def apply_gaussian(image):
    """Apply Gaussian filter."""
    return nd.gaussian_filter(image, sigma=1)

def apply_sobel(image):
    """Apply Sobel filter."""
    return sobel(image)

def apply_gabor(image):
    """Apply Gabor filter (return magnitude)."""
    return gabor(image, frequency=0.9)[1]

def apply_hessian(image):
    """Apply Hessian filter over a range of sigmas."""
    return hessian(image, sigmas=range(1, 100, 1))

def apply_prewitt(image):
    """Apply Prewitt filter."""
    return prewitt(image)

# ------------------------------------------------------------------
# 2. Global Lock for Thread-Safe Access
#    (If you're writing to shared memory, a database, or logs.)
# ------------------------------------------------------------------
results_lock = threading.Lock()

# ------------------------------------------------------------------
# 3. Apply All Filters in Parallel (Thread Pool)
# ------------------------------------------------------------------
def apply_all_filters_threaded(image):
    """
    Apply all filters in parallel using a ThreadPoolExecutor.
    This function runs *inside* a single worker process.
    """

    # Store results in a local dictionary
    filter_results = {}

    # This helper captures filter results under a lock
    def run_filter_and_store(filter_func, img):
        result = filter_func(img)
        # If you need to safely store to a shared structure, lock here
        with results_lock:
            filter_results[filter_func.__name__] = result
    
    # List of filter functions
    filters = [
        apply_entropy,
        apply_gaussian,
        apply_sobel,
        apply_gabor,
        apply_hessian,
        apply_prewitt
    ]

    # Create a thread pool for these filters
    with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()//2) as t_executor:
        futures = []
        for f in filters:
            futures.append(t_executor.submit(run_filter_and_store, f, image))

        # Wait for all filters to finish
        for future in as_completed(futures):
            pass

    return filter_results

# ------------------------------------------------------------------
# 4. Process One Image
# ------------------------------------------------------------------
def process_single_image(image):
    """
    Called once per image by the top-level process pool.
    Inside, we use threads to apply each filter in parallel.
    """
    filter_results = apply_all_filters_threaded(image)
    result = {
        'Original': image,
        **filter_results  # Merge filter outputs into a single dict
    }
    return result

# ------------------------------------------------------------------
# 5. Parallel Execution for a List of Images (Process Pool)
# ------------------------------------------------------------------
def process_images_parallel(images):
    """
    Parallelize across images using a ProcessPoolExecutor.
    Each worker will call 'process_single_image' to do filters in parallel (threads).
    """
    num_cores = multiprocessing.cpu_count()

    with ProcessPoolExecutor(max_workers=num_cores) as executor:
        # For demonstration, we limit to first 5 images in the tqdm call
        futures = executor.map(process_single_image, images[:5])
        results = list(tqdm(futures, total=min(len(images), 5)))

    return results

# ------------------------------------------------------------------
# 6. Example Usage
# ------------------------------------------------------------------
# Assume `yes_images`, `no_images` are lists/arrays of images.
# And `execution_time` is from your sequential code for speedup reference.

# Suppose 'yes_images' and 'no_images' are defined elsewhere
# yes_images = [...]
# no_images = [...]

start_time = time.time()
yes_inputs_parallel = process_images_parallel(yes_images)
no_inputs_parallel = process_images_parallel(no_images)
end_time = time.time()

parallel_execution_time = end_time - start_time
print(f"Parallel execution time: {parallel_execution_time:.2f} seconds")

# Calculate speedup (assuming you've defined `execution_time` for the sequential version)
speedup = execution_time / parallel_execution_time
efficiency = speedup / multiprocessing.cpu_count()

print(f"Speedup: {speedup:.2f}x")
print(f"Efficiency: {efficiency:.2f}")





## Your analysis here (Convert this to markdown).





## The Code exemple
import numpy as np
import pandas as pd
import skimage.feature as feature

# Function to compute GLCM features for an image
def compute_glcm_features(image, 
                                                    filter_name):
    """
    Computes GLCM (Gray Level Co-occurrence Matrix) features for an image.

    Parameters:
    - image: A 2D array representing the image. Should be in grayscale.
    - filter_name: A string representing the name of the filter applied to the image.

    Returns:
    - features: A dictionary containing the computed GLCM features. The keys are
        formatted as "{filter_name}_{feature_name}_{angle_index}", where "angle_index"
        corresponds to the index of the angle used for the GLCM calculation (1-based).
        The features include contrast, dissimilarity, homogeneity, energy, correlation,
        and ASM (Angular Second Moment) for each angle (0, π/4, π/2, 3π/4).

    Notes:
    - The image is first converted from float to uint8 format, as the graycomatrix
        function expects integer values.
    - The GLCM is computed using four angles (0, π/4, π/2, 3π/4) with a distance of 1.
    - The GLCM properties are computed and flattened into a 1D array to handle multiple
        angles. Each property value for each angle is stored as a separate key in the
        resulting dictionary.
    """
    # Convert the image from float to int
    image = (image * 255).astype(np.uint8)

    # Compute the GLCM
    graycom = feature.graycomatrix(image, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256, symmetric=True, normed=True)

    # Compute GLCM properties
    features = {}
    for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']:
            values = feature.graycoprops(graycom, prop).flatten()
            for i, value in enumerate(values):
                    features[f'{filter_name}_{prop}_{i+1}'] = value
    return features


def process_images(images_list, tumor_presence):
    """
    Processes a list of images, applies all filters, computes GLCM features, and adds a "Tumor" key.

    Parameters:
    - images_list: A list of dictionaries, where each dictionary contains filtered images with keys
      representing the filter names.
    - tumor_presence: An integer (0 or 1) indicating the presence (1) or absence (0) of a tumor.

    Returns:
    - glcm_features_list: A list of dictionaries, where each dictionary contains the GLCM features for
      all filtered images of one original image and a "Tumor" key indicating the presence or absence
      of a tumor.

    Notes:
    - The function iterates over each image in the input list. For each image, it applies all filters
      and computes the GLCM features using the compute_glcm_features function.
    - The "Tumor" key is added to each dictionary to indicate whether the image is from the "yes" (tumor)
      or "no" (no tumor) list.
    - The resulting list of dictionaries can be used to create a pandas DataFrame for machine learning
      tasks.
    """
    # Apply all filters to each image and compute GLCM features
    glcm_features_list = []
    for filtered_images in images_list:
        glcm_features = {}
        for key, image in filtered_images.items():
            glcm_features.update(compute_glcm_features(image, key))
        glcm_features['Tumor'] = tumor_presence
        glcm_features_list.append(glcm_features)
    return glcm_features_list



# Process the 'yes' and 'no' image lists
yes_glcm_features = process_images(yes_inputs, 1)
no_glcm_features = process_images(no_inputs, 0)

# Combine the features into a single list
all_glcm_features = yes_glcm_features + no_glcm_features

# Convert the list of dictionaries to a pandas DataFrame
dataframe = pd.DataFrame(all_glcm_features)

# Print the first few rows of the DataFrame
print(dataframe.shape)

# Shuffle the DataFrame
shuffled_dataframe = dataframe.sample(frac=1).reset_index(drop=True)

# Print the first few rows of the shuffled DataFrame
print(shuffled_dataframe.head())





## Add your code here





# Have fun here.
