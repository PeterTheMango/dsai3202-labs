{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea5599c-5ad7-41b6-be9f-108184c4ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from threading import Thread\n",
    "from multiprocessing import Process, Queue\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b14420e-9853-4535-a271-fbff73b84973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "raw_data = pd.read_csv('train.csv', index_col=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b445528a-a43e-496b-9b20-f0336391ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Data\n",
    "\n",
    "def remove_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    numerical_columns = cleaned_data.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    cleaned_df = df[(df[numerical_columns] >= lower_bound) & (df[numerical_columns] <= upper_bound)]\n",
    "    cleaned_df = cleaned_df.dropna()\n",
    "    return cleaned_df\n",
    "\n",
    "def remove_skew(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "    for col in df.columns:\n",
    "        skew_val = df[col].skew()\n",
    "        if skew_val > 0:\n",
    "            if df[col].min() <= 0:\n",
    "                shift = abs(df[col].min()) + 1\n",
    "                df[col] = np.log(df[col] + shift)\n",
    "            else:\n",
    "                df[col] = np.log(df[col])\n",
    "        elif skew_val < 0:\n",
    "            if df[col].min() < 0:\n",
    "                shift = abs(df[col].min())\n",
    "                df[col] = np.sqrt(df[col] + shift)\n",
    "            else:\n",
    "                df[col] = np.sqrt(df[col])\n",
    "    return df\n",
    "\n",
    "columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', \"PoolArea\", \"BsmtFinType2\", \"2ndFlrSF\", \"BsmtFinSF1\", \"1stFlrSF\", \"HalfBath\", \"WoodDeckSF\",\"GrLivArea\", \"BsmtFullBath\", \"BedroomAbvGr\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\"]\n",
    "cleaned_data = raw_data.drop(columns=columns_to_delete, axis=1)\n",
    "\n",
    "numerical_columns = cleaned_data.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = cleaned_data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "cleaned_data[numerical_columns] = remove_outliers(cleaned_data[numerical_columns])\n",
    "cleaned_data[numerical_columns] = remove_skew(cleaned_data[numerical_columns])\n",
    "\n",
    "\n",
    "mode_values = cleaned_data[categorical_columns].mode().iloc[0]\n",
    "cleaned_data.loc[:, categorical_columns] = cleaned_data.loc[:, categorical_columns].fillna(mode_values)\n",
    "\n",
    "mean_values = cleaned_data[numerical_columns].mean()\n",
    "cleaned_data.loc[:, numerical_columns] = cleaned_data.loc[:, numerical_columns].fillna(mean_values)\n",
    "\n",
    "cleaned_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10efe495-b947-45fb-84a4-a02c2eddc6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1013, 56), (435, 56), (1013,), (435,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Data\n",
    "X = cleaned_data.drop('SalePrice', axis=1)\n",
    "y = cleaned_data['SalePrice']\n",
    "\n",
    "label_encoders = {column: LabelEncoder() for column in categorical_columns}\n",
    "for column in categorical_columns:\n",
    "    X[column] = label_encoders[column].fit_transform(X[column])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "X_train_filled = X_train.fillna(X_train.mean())\n",
    "X_val_filled = X_val.fillna(X_val.mean())\n",
    "\n",
    "(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1089b045-34de-4c49-8043-6b0423b13a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 7/7 [00:33<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters {'n_estimators': 50, 'max_features': None, 'max_depth': 10}\n",
      "RMSE = 0.08475464314752809\n",
      "MAPE = 0.315009643239149%\n",
      "The sequential execution time is 33.902761936187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sequential Processing\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "for n_estimators in tqdm(n_estimators_range):\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf_model.fit(X_train_filled, y_train)\n",
    "            \n",
    "            # Make predictions and compute RMSE\n",
    "            y_val_pred = rf_model.predict(X_val_filled)\n",
    "            rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_mape = mape\n",
    "                best_model = rf_model\n",
    "                best_params = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth\n",
    "                }\n",
    "print(f\"The best parameters {best_params}\\nRMSE = {best_rmse}\\nMAPE = {best_mape}%\")\n",
    "end_time = time.time()\n",
    "sequential_time = end_time - start_time\n",
    "print(f\"The sequential execution time is {sequential_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ab70fd-9463-49a7-91b5-3f49aed0d5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for threads to finish: 100%|███████████████████████████████████████████████| 126/126 [00:18<00:00,  6.96it/s]\n",
      "Anlyzing results: 100%|███████████████████████████████████████████████████████| 126/126 [00:00<00:00, 1311370.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters {'n_estimators': 50, 'max_features': None, 'max_depth': 10}\n",
      "RMSE = 0.08475464314752809\n",
      "MAPE = 0.315009643239149%\n",
      "Thread Parallel execution time is 22.072564363479614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Threading Processing\n",
    "non_par_thread_start = time.time()\n",
    "def test_model(n_estimators= 100, \n",
    "                   max_features='auto', \n",
    "                   max_depth= None, \n",
    "                   results=[], \n",
    "                   index= 0) -> None:\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_filled, y_train)\n",
    "    \n",
    "    y_val_pred = rf_model.predict(X_val_filled)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "    \n",
    "    results[index] = (n_estimators, max_features, max_depth, rmse, mape)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = [None] * (len(n_estimators_range) * len(max_features_range) * len(max_depth_range))\n",
    "\n",
    "threads = []\n",
    "index = 0\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            thread = Thread(target=test_model, args=(n_estimators,\n",
    "                                                         max_features,\n",
    "                                                         max_depth,\n",
    "                                                         results,\n",
    "                                                         index))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "            index += 1\n",
    "\n",
    "for thread in tqdm(threads, desc=\"Waiting for threads to finish: \"):\n",
    "    thread.join()\n",
    "\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "for n_estimators, max_features, max_depth, rmse, mape in tqdm(results, desc=\"Anlyzing results: \"):\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_mape = mape\n",
    "        best_params = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_features': max_features,\n",
    "            'max_depth': max_depth\n",
    "        }\n",
    "\n",
    "print(f\"The best parameters {best_params}\\nRMSE = {best_rmse}\\nMAPE = {best_mape}%\")\n",
    "end_time = time.time()\n",
    "threading_time = end_time - start_time\n",
    "print(f\"Thread Parallel execution time is {threading_time}\")\n",
    "non_par_thread_end = time.time()\n",
    "non_par_thread = non_par_thread_end - non_par_thread_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cfa13d8-98b9-43d7-895d-24de9bcbef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_par_proc_start = time.time()\n",
    "def proc_model(n_estimators= 100, \n",
    "                   max_features= 'auto', \n",
    "                   max_depth= 1, \n",
    "                   result_queue=None) -> None:\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_filled, y_train)\n",
    "    \n",
    "\n",
    "    y_val_pred = rf_model.predict(X_val_filled)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "    \n",
    "\n",
    "    result_dictionary = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape\n",
    "    }\n",
    "    \n",
    "    if result_queue is not None:\n",
    "        result_queue.put(result_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff3f1c89-bc01-4102-91c6-9d153fa9ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for processes to finish: 100%|█████████████████████████████████████████████| 126/126 [00:03<00:00, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters {'n_estimators': 50, 'max_features': None, 'max_depth': 10}\n",
      "RMSE = 0.08475464314752809\n",
      "MAPE = 0.315009643239149%\n",
      "The processes parallel execution time is 7.320642471313477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MultiProcess Processing\n",
    "\n",
    "start_time = time.time()  \n",
    "\n",
    "processes = []\n",
    "queue = Queue()\n",
    "\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            file_path = f'results_{n_estimators}_{max_features}_{max_depth}.json'\n",
    "            process = Process(target=proc_model,\n",
    "                              args=(n_estimators,\n",
    "                                    max_features,\n",
    "                                    max_depth,\n",
    "                                    queue))\n",
    "            processes.append(process)\n",
    "            process.start()\n",
    "\n",
    "\n",
    "for process in tqdm(processes, desc=\"Waiting for processes to finish: \"):\n",
    "    process.join()\n",
    "\n",
    "\n",
    "results = []\n",
    "while not queue.empty():\n",
    "    results.append(queue.get())\n",
    "\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "\n",
    "for res in results:\n",
    "    if res['rmse'] < best_rmse:\n",
    "        best_rmse = res['rmse']\n",
    "        best_mape = res['mape']\n",
    "        best_params = {\n",
    "            'n_estimators': res['n_estimators'],\n",
    "            'max_features': res['max_features'],\n",
    "            'max_depth': res['max_depth']\n",
    "        }\n",
    "\n",
    "print(f\"The best parameters {best_params}\\nRMSE = {best_rmse}\\nMAPE = {best_mape}%\")\n",
    "\n",
    "end_time = time.time()\n",
    "processes_time = end_time - start_time\n",
    "print(f\"The processes parallel execution time is {processes_time}\")\n",
    "\n",
    "non_par_proc_end = time.time()\n",
    "non_par_proc = non_par_proc_end - non_par_proc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa7c474-1556-45f2-875d-02a1767adf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c218bec-5cd6-4f89-9c15-da085951c16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threading speedup: 1.5359684256842356.\n"
     ]
    }
   ],
   "source": [
    "number_of_cpus = os.cpu_count()\n",
    "\n",
    "speedup_threading = sequential_time / threading_time\n",
    "print(f\"Threading speedup: {speedup_threading}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66630fc0-8d91-4230-b08a-0921ec9e0a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing Speedup:  4.631118384627911.\n"
     ]
    }
   ],
   "source": [
    "speedup_processes = sequential_time / processes_time\n",
    "print(f\"Multiprocessing Speedup:  {speedup_processes}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1af0d8-f645-47ac-97cb-cd1c6986f662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threading efficiency: 0.2559947376140393.\n"
     ]
    }
   ],
   "source": [
    "efficiency_threading = speedup_threading / number_of_cpus\n",
    "print(f\"Threading efficiency: {efficiency_threading}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9838aeb3-8742-4bab-bf3b-0ca3c7286e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Efficiency: 0.7718530641046518.\n"
     ]
    }
   ],
   "source": [
    "efficiency_processes = speedup_processes / number_of_cpus\n",
    "print(f\"Processing Efficiency: {efficiency_processes}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e6f8ff4-fa77-4bef-b931-6548b315ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amdhal Threading speedup: 1.535955484901813.\n"
     ]
    }
   ],
   "source": [
    "non_parallel_time = non_par_thread\n",
    "parallel_portion = 1 - (non_parallel_time / sequential_time)\n",
    "S_amdhal = 1 / (1 - parallel_portion)\n",
    "print(f\"Amdhal Threading speedup: {S_amdhal}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fee815d6-a7f9-4fa9-a856-56985a8f3fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Amdhal Threading speedup: 1.4100054583755053.\n"
     ]
    }
   ],
   "source": [
    "S_amdhal = 1 / ((1 - parallel_portion) + (parallel_portion / number_of_cpus))\n",
    "print(f\"New Amdhal Threading speedup: {S_amdhal}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7724d58f-f234-48e0-adeb-53072b8da6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gustafson Threading speedup: 2.7446973241417685.\n"
     ]
    }
   ],
   "source": [
    "S_gustafson = (1 - parallel_portion) + (parallel_portion * number_of_cpus)\n",
    "print(f\"Gustafson Threading speedup: {S_gustafson}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c32352b5-ee43-42b9-845b-8327e2a34681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amdhal Process speedup: 4.628030016771092.\n"
     ]
    }
   ],
   "source": [
    "non_parallel_time = non_par_proc\n",
    "parallel_portion = 1 - (non_parallel_time / sequential_time)\n",
    "S_amdhal = 1 / (1 - parallel_portion)\n",
    "print(f\"Amdhal Process speedup: {S_amdhal}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26eb2228-7375-46e0-bdb4-b3b8082941d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Amdhal Process speedup: 2.8840977907481675.\n"
     ]
    }
   ],
   "source": [
    "S_amdhal = 1 / ((1 - parallel_portion) + (parallel_portion / number_of_cpus))\n",
    "print(f\"New Amdhal Process speedup: {S_amdhal}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd6451fc-5b58-4b50-a26d-d684dc58528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gustafson Process speedup: 4.919626713335704.\n"
     ]
    }
   ],
   "source": [
    "S_gustafson = (1 - parallel_portion) + (parallel_portion * number_of_cpus)\n",
    "print(f\"Gustafson Process speedup: {S_gustafson}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53326de-e1db-4113-9eff-74067b0e2fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
